{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd1b0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08d1f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 2500  # 입력 문장에서 사용할 단어(또는 토큰) 수\n",
    "tgt_vocab = 3000  # 출력 문장에서 사용할 단어(또는 토큰) 수\n",
    "d_model = 512  # 단어 임베딩 벡터 차원 (단어를 몇 차원으로 표현할지)\n",
    "num_heads = 8  # 멀티 헤드 어텐션에서의 헤드 수 (병렬로 몇 개의 어텐션을 계산할지)\n",
    "num_layers = 6  # 인코더와 디코더의 층 수 (각각 몇 층으로 구성할지)\n",
    "\n",
    "d_ff = 2048  # Feed Forward 네트워크의 은닉층 크기\n",
    "max_seq = 100  # 문장의 최대 길이 (100 토큰까지 허용)\n",
    "tot_epoch = 4  # 학습 데이터 전체를 몇 번 반복할지 (에폭 수)\n",
    "batch_size = 5  # 학습할 때 한 번에 처리할 문장 수 (배치 크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39320bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 모양 torch.Size([5, 100])\n",
      "tensor([ 684, 2232, 1393,  516, 1232,   38, 2313,  937, 1295,  413,  146,    5,\n",
      "         583, 1656, 1321,  328,  664,  484,  808, 1208, 1839, 2207,  316, 2005,\n",
      "        2412,  701,  519, 1068, 2245,  278, 1226, 1153, 1008,  645, 2222,  295,\n",
      "         959, 1227,  121, 1013,  421, 2171,  388,  568, 1321, 1142,  365, 1370,\n",
      "         227, 1767,  281, 2167, 1590, 2490, 1745, 1545, 2310,  379, 1686, 2059,\n",
      "         987,  944,  964,  824, 1014, 1998, 1110,  142,  364, 2079, 1331,  131,\n",
      "         944, 1172,  989,  387,  305, 1626,  902, 1436,  472, 1263, 1787,  494,\n",
      "         920,  118, 1954, 1909,  835, 1174, 1639,  614, 2283, 2128,  448, 1479,\n",
      "         207, 2218, 1392, 2363])\n"
     ]
    }
   ],
   "source": [
    "# 3번 블럭\n",
    "# 데이터 임의 생성\n",
    "\n",
    "# 입력 데이터 (src_data) 생성\n",
    "# 0부터 src_vocab(2500) 미만의 숫자 중에서 랜덤하게 선택\n",
    "# 크기: (batch_size, max_seq) → 5개의 문장, 각 문장은 100단어\n",
    "src_data = torch.randint(0, src_vocab, (batch_size, max_seq))\n",
    "print(f\"입력 데이터 모양 {src_data.shape}\")\n",
    "print(src_data[0])\n",
    "\n",
    "# 출력 데이터 (tgt_data) 생성\n",
    "# 0부터 tgt_vocab(3000) 미만의 숫자 중에서 랜덤하게 선택\n",
    "# 크기: (batch_size, max_seq)\n",
    "tgt_data = torch.randint(0, tgt_vocab, (batch_size, max_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4번 블럭\n",
    "# Multi-head attention class 구현\n",
    "class My_MHA(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(My_MHA, self).__init__()\n",
    "        self.d_model = d_model  # 512 차원\n",
    "        self.num_heads = num_heads  # 헤드 8개\n",
    "\n",
    "        # 각 헤드 당 처리할 차원 수\n",
    "        # 총 512 개의 차원을 8개의 헤드가 나눠서 처리하기때문에 각 헤드당 64차원 처리함\n",
    "        self.d_head = d_model // num_heads\n",
    "\n",
    "        # Q,K,V 행렬 준비 (W_Q, W_K, W_V에 학습가능 파라미터 262,656개 모델 생성)\n",
    "        self.W_Q = nn.Linear(\n",
    "            d_model, d_model\n",
    "        )  # 512 입력 512 출력 (512*512+512=262,656)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "\n",
    "    # 머리나누기\n",
    "    # 입력 데이터 모양 : [5, 100, 512]\n",
    "    # 출력 데이터 모양 : [5, 8, 100, 64]\n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # 데이터 모양 : [5, 100, 8, 64]\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.d_head)\n",
    "        x = x.transpose(1, 2)  # 헤드별로 처리하기 위한 교환\n",
    "        return x\n",
    "\n",
    "    # 유사성 계산\n",
    "    def dot_prod(self, Q, K, V, mask):\n",
    "        score = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(self.d_head)\n",
    "\n",
    "        # 디코더 마스크 처리\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -1e9)\n",
    "        prob = torch.softmax(score, dim=-1)\n",
    "\n",
    "        # V 행렬과 곱셈\n",
    "        Z = torch.matmul(prob, V)\n",
    "        return Z\n",
    "\n",
    "    # 머리 합치기\n",
    "    # 입력데이터 모양 : [5, 8, 100, 64]\n",
    "    # 출력 데이터 모양 : [5, 100, 512]\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # 데이터 모양 : [5,100,8,64]\n",
    "        Z = x.transpose(1, 2)\n",
    "\n",
    "        # 데이터 모양 : [5, 100, 512], 입력과 동일한 출력형태\n",
    "        Z = Z.contiguous().view(batch_size, -1, self.d_model)\n",
    "        return Z\n",
    "\n",
    "    # 앞서 정의한 함수로 forward를 정의\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # 머리 나누기 실행/생성된 모델에 임베딩된 토큰(문자열 q,k,v) 입력\n",
    "        Q = self.split_heads(self.W_Q(q))\n",
    "        K = self.split_heads(self.W_K(k))\n",
    "        V = self.split_heads(self.W_V(v))\n",
    "\n",
    "        # 유사성 계산 실행\n",
    "        attn = self.dot_prod(Q, K, V, mask)\n",
    "\n",
    "        # 머리 합치기 실행\n",
    "        Z = self.combine_heads(attn)\n",
    "\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351a880",
   "metadata": {},
   "source": [
    "## 🔍 Multi-Head Attention 클래스 흐름 정리\n",
    "\n",
    "### ✅ 1. 입력된 단어를 512차원으로 벡터화\n",
    "```python\n",
    "self.W_Q(q)\n",
    "```\n",
    "- 입력 임베딩 벡터 `q`에 선형 변환(`W_Q`, `W_K`, `W_V`)을 적용해서  \n",
    "  각각 Query, Key, Value 벡터를 생성한다.\n",
    "- 입력 shape: `[batch_size, seq_len, d_model]` → 예: `[5, 100, 512]`\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 2. 설정된 헤드로 Q, K, V를 나눔 (차원 변환 포함)\n",
    "```python\n",
    "Q = self.split_heads(self.W_Q(q))\n",
    "```\n",
    "- 512차원을 8개의 head로 쪼갬 → 각 head는 64차원씩 담당.\n",
    "- shape 변화: `[5, 100, 512]` → `[5, 8, 100, 64]`\n",
    "- `transpose(1, 2)`를 통해 head 차원을 앞으로 이동시켜 병렬 연산이 가능하게 함.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3. Q, K, V 계산 → 어텐션 연산 수행\n",
    "```python\n",
    "attn = self.dot_prod(Q, K, V, mask)\n",
    "```\n",
    "- 어텐션 스코어 계산: `score = Q @ Kᵀ / sqrt(d_head)`\n",
    "- 마스크(mask)가 있을 경우 적용.\n",
    "- `softmax(score)`를 통해 확률적 가중치 구함.\n",
    "- `Z = softmax(score) @ V` 계산으로 최종 attention 결과 획득.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 4. 계산한 결과를 다시 하나로 합침\n",
    "```python\n",
    "Z = self.combine_heads(attn)\n",
    "```\n",
    "- shape 변화: `[5, 8, 100, 64]` → `[5, 100, 512]`\n",
    "- 여러 head에서 계산된 결과를 다시 원래 차원(d_model=512)으로 합침.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 한 줄 요약\n",
    "> 입력 임베딩을 Q, K, V로 만들어 head마다 attention을 따로 계산하고,  \n",
    "> 다시 합쳐서 더 풍부한 문맥 정보를 가진 출력으로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ee299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5번 블럭\n",
    "# feed forward (순전파) class 구현\n",
    "\n",
    "\n",
    "class My_FFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(My_FFN, self).__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059234fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6번 블럭\n",
    "# 자연어 트랜스포머 인코더 구현\n",
    "\n",
    "\n",
    "class My_Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(My_Encoder, self).__init__()\n",
    "\n",
    "        self.mha = My_MHA(d_model, num_heads)\n",
    "        self.ffn = My_FFN(d_model, d_ff)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        z = self.mha(x, x, x, mask)\n",
    "        z = self.layer_norm(x + z)  # 잔차 연결\n",
    "        w = self.ffn(z)\n",
    "        z = self.layer_norm(w + z)  # 레이어 정규화, 잔차 연결\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7번 블럭\n",
    "# 위치 인코딩 구현\n",
    "\n",
    "\n",
    "class My_Position(nn.Module):\n",
    "    def __init__(self, d_model, max_seq):\n",
    "        super(My_Position, self).__init__()\n",
    "\n",
    "        self.d_model = d_model  # 512 차원\n",
    "        self.max_seq = max_seq  # 입력 문장 최대길이 100\n",
    "\n",
    "    # 위치 임베딩 계산\n",
    "    def pos_enc(self, x):\n",
    "        k = torch.arange(0, self.max_seq, 1).float()  # 0부터 100까지의 실수\n",
    "        print(\"전\", k.shape)  # [100]\n",
    "        k = k.unsqueeze(1)\n",
    "        print(\"후\", k.shape)  # [100, 1] 2차원 텐서로 변형\n",
    "        result = torch.zeros(self.max_seq, self.d_model)\n",
    "        print(\n",
    "            \"결과\", result.shape\n",
    "        )  # [100, 512] 텐서 공간에 0으로 세팅, 포지셔널 벡터용 공간\n",
    "        twoi = torch.arange(0, self.d_model, 2).float()  # 512 차원의 짝수 인덱스 생성\n",
    "        print(twoi)\n",
    "\n",
    "        result[:, 0::2] = torch.sin(\n",
    "            k / (10000 ** (twoi / self.d_model))\n",
    "        )  # k 는 입력 토큰\n",
    "        result[:, 1::2] = torch.cos(k / 10000 ** (twoi / self.d_model))\n",
    "        result = result.unsqueeze(0)\n",
    "        print(\"최종 모양\", result.shape)\n",
    "        return result\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos = self.pos_enc(x)\n",
    "        return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8번 블럭\n",
    "# 디코더구현\n",
    "class My_Decoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(My_Decoder, self).__init__()\n",
    "        self.mha_1 = My_MHA(d_model, num_heads)\n",
    "        self.mha_2 = My_MHA(d_model, num_heads)\n",
    "        self.ffn = My_FFN(d_model, d_ff)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, tgt_mask):\n",
    "        print(\"디코더입력데이터모양\", x.shape)\n",
    "        # 디코더self attention 부분\n",
    "        z = self.mha_1(x, x, x, tgt_mask)\n",
    "        z = self.layer_norm(x + z)\n",
    "        print(\"self attention 후데이터모양\", x.shape)\n",
    "\n",
    "        # 디코더 cross attention 부분\n",
    "        y = self.mha_2(z, enc_out, enc_out, src_mask)\n",
    "        y = self.layer_norm(z + y)\n",
    "        print(\"cross attention 후 데이터 모양\", y.shape)\n",
    "\n",
    "        # 마지막feed forward 부분\n",
    "        w = self.ffn(y)\n",
    "        z = self.layer_norm(w + y)\n",
    "        print(\"feed forward 후데이터모양\", z.shape)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4215a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9번 블럭\n",
    "# 전체 자연어 트랜스포머 구성\n",
    "\n",
    "\n",
    "class My_Transformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_layers, d_ff, max_seq):\n",
    "        super(My_Transformer, self).__init__()\n",
    "\n",
    "        self.enc_embed = nn.Embedding(src_vocab, d_model)\n",
    "        self.dec_embed = nn.Embedding(tgt_vocab, d_model)\n",
    "        self.pos_enc = My_Position(d_model, max_seq)\n",
    "\n",
    "        # 인코더 쌓기\n",
    "        self.enc_layers = nn.ModuleList(\n",
    "            [My_Encoder(d_model, num_heads, d_ff) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        # 디코더 쌓기\n",
    "        self.dec_layers = nn.ModuleList(\n",
    "            [My_Decoder(d_model, num_heads, d_ff) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        # 최종 출력층\n",
    "        self.linear = nn.Linear(d_model, tgt_vocab)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # 디코더 마스크 제작\n",
    "    def make_mask(self, src, tgt):\n",
    "        src_mask = None\n",
    "        tgt_mask = tgt.unsqueeze(1).unsqueeze(3)\n",
    "        tmp = torch.ones(1, max_seq, max_seq)\n",
    "        mask = torch.tril(tmp).bool()\n",
    "        print(\"틀\", mask)\n",
    "\n",
    "        tgt_mask = tgt_mask * mask\n",
    "        print(\"마스크 모양\", tgt_mask.shape)\n",
    "        print(\"마스크 결과\", tgt_mask)\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # 마스크 만들기\n",
    "        src_mask, tgt_mask = self.make_mask(src, tgt)\n",
    "        print(\"마스크 모양\", tgt_mask.shape)\n",
    "        print(tgt_mask[1])\n",
    "\n",
    "        # 단어 임베딩 및 위치 정보 추가\n",
    "        src_embed = self.enc_embed(src)\n",
    "        tgt_embed = self.dec_embed(tgt)\n",
    "        src_pos = self.pos_enc(src)\n",
    "        tgt_pos = self.pos_enc(tgt)\n",
    "        src_embed = src_embed + src_pos\n",
    "        tgt_embed = tgt_embed + tgt_pos\n",
    "\n",
    "        # 인코더 연결\n",
    "        # print('인코더 입력 모양', src_embed.shape)\n",
    "        enc_out = src_embed\n",
    "        for layer in self.enc_layers:\n",
    "            enc_out = layer(enc_out, src_mask)\n",
    "        # print('인코더 출력 모양', enc_out.shape)\n",
    "\n",
    "        # 디코더 연결\n",
    "        dec_out = tgt_embed\n",
    "        for layer in self.dec_layers:\n",
    "            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n",
    "\n",
    "        # 최종 출력\n",
    "        out = self.linear(dec_out)\n",
    "        out = self.softmax(out)\n",
    "        out = torch.argmax(out, dim=-1)\n",
    "        print(\"최종 출력 모양\", out.shape)\n",
    "        print(\"최종 출력 내용\", out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "736d3687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prettytable in c:\\users\\main\\miniconda3\\envs\\openai_api_part1\\lib\\site-packages (3.16.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\main\\miniconda3\\envs\\openai_api_part1\\lib\\site-packages (from prettytable) (0.2.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ff2ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번 블럭\n",
    "# 가중치 수 출력하기\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"전체 모델 가중치 수: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4d70337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+------------+\n",
      "|             Modules              | Parameters |\n",
      "+----------------------------------+------------+\n",
      "|         enc_embed.weight         |  1280000   |\n",
      "|         dec_embed.weight         |  1536000   |\n",
      "|   enc_layers.0.mha.W_Q.weight    |   262144   |\n",
      "|    enc_layers.0.mha.W_Q.bias     |    512     |\n",
      "|   enc_layers.0.mha.W_K.weight    |   262144   |\n",
      "|    enc_layers.0.mha.W_K.bias     |    512     |\n",
      "|   enc_layers.0.mha.W_V.weight    |   262144   |\n",
      "|    enc_layers.0.mha.W_V.bias     |    512     |\n",
      "| enc_layers.0.ffn.linear_1.weight |  1048576   |\n",
      "|  enc_layers.0.ffn.linear_1.bias  |    2048    |\n",
      "| enc_layers.0.ffn.linear_2.weight |  1048576   |\n",
      "|  enc_layers.0.ffn.linear_2.bias  |    512     |\n",
      "|  enc_layers.0.layer_norm.weight  |    512     |\n",
      "|   enc_layers.0.layer_norm.bias   |    512     |\n",
      "|   enc_layers.1.mha.W_Q.weight    |   262144   |\n",
      "|    enc_layers.1.mha.W_Q.bias     |    512     |\n",
      "|   enc_layers.1.mha.W_K.weight    |   262144   |\n",
      "|    enc_layers.1.mha.W_K.bias     |    512     |\n",
      "|   enc_layers.1.mha.W_V.weight    |   262144   |\n",
      "|    enc_layers.1.mha.W_V.bias     |    512     |\n",
      "| enc_layers.1.ffn.linear_1.weight |  1048576   |\n",
      "|  enc_layers.1.ffn.linear_1.bias  |    2048    |\n",
      "| enc_layers.1.ffn.linear_2.weight |  1048576   |\n",
      "|  enc_layers.1.ffn.linear_2.bias  |    512     |\n",
      "|  enc_layers.1.layer_norm.weight  |    512     |\n",
      "|   enc_layers.1.layer_norm.bias   |    512     |\n",
      "|   enc_layers.2.mha.W_Q.weight    |   262144   |\n",
      "|    enc_layers.2.mha.W_Q.bias     |    512     |\n",
      "|   enc_layers.2.mha.W_K.weight    |   262144   |\n",
      "|    enc_layers.2.mha.W_K.bias     |    512     |\n",
      "|   enc_layers.2.mha.W_V.weight    |   262144   |\n",
      "|    enc_layers.2.mha.W_V.bias     |    512     |\n",
      "| enc_layers.2.ffn.linear_1.weight |  1048576   |\n",
      "|  enc_layers.2.ffn.linear_1.bias  |    2048    |\n",
      "| enc_layers.2.ffn.linear_2.weight |  1048576   |\n",
      "|  enc_layers.2.ffn.linear_2.bias  |    512     |\n",
      "|  enc_layers.2.layer_norm.weight  |    512     |\n",
      "|   enc_layers.2.layer_norm.bias   |    512     |\n",
      "|   enc_layers.3.mha.W_Q.weight    |   262144   |\n",
      "|    enc_layers.3.mha.W_Q.bias     |    512     |\n",
      "|   enc_layers.3.mha.W_K.weight    |   262144   |\n",
      "|    enc_layers.3.mha.W_K.bias     |    512     |\n",
      "|   enc_layers.3.mha.W_V.weight    |   262144   |\n",
      "|    enc_layers.3.mha.W_V.bias     |    512     |\n",
      "| enc_layers.3.ffn.linear_1.weight |  1048576   |\n",
      "|  enc_layers.3.ffn.linear_1.bias  |    2048    |\n",
      "| enc_layers.3.ffn.linear_2.weight |  1048576   |\n",
      "|  enc_layers.3.ffn.linear_2.bias  |    512     |\n",
      "|  enc_layers.3.layer_norm.weight  |    512     |\n",
      "|   enc_layers.3.layer_norm.bias   |    512     |\n",
      "|   enc_layers.4.mha.W_Q.weight    |   262144   |\n",
      "|    enc_layers.4.mha.W_Q.bias     |    512     |\n",
      "|   enc_layers.4.mha.W_K.weight    |   262144   |\n",
      "|    enc_layers.4.mha.W_K.bias     |    512     |\n",
      "|   enc_layers.4.mha.W_V.weight    |   262144   |\n",
      "|    enc_layers.4.mha.W_V.bias     |    512     |\n",
      "| enc_layers.4.ffn.linear_1.weight |  1048576   |\n",
      "|  enc_layers.4.ffn.linear_1.bias  |    2048    |\n",
      "| enc_layers.4.ffn.linear_2.weight |  1048576   |\n",
      "|  enc_layers.4.ffn.linear_2.bias  |    512     |\n",
      "|  enc_layers.4.layer_norm.weight  |    512     |\n",
      "|   enc_layers.4.layer_norm.bias   |    512     |\n",
      "|   enc_layers.5.mha.W_Q.weight    |   262144   |\n",
      "|    enc_layers.5.mha.W_Q.bias     |    512     |\n",
      "|   enc_layers.5.mha.W_K.weight    |   262144   |\n",
      "|    enc_layers.5.mha.W_K.bias     |    512     |\n",
      "|   enc_layers.5.mha.W_V.weight    |   262144   |\n",
      "|    enc_layers.5.mha.W_V.bias     |    512     |\n",
      "| enc_layers.5.ffn.linear_1.weight |  1048576   |\n",
      "|  enc_layers.5.ffn.linear_1.bias  |    2048    |\n",
      "| enc_layers.5.ffn.linear_2.weight |  1048576   |\n",
      "|  enc_layers.5.ffn.linear_2.bias  |    512     |\n",
      "|  enc_layers.5.layer_norm.weight  |    512     |\n",
      "|   enc_layers.5.layer_norm.bias   |    512     |\n",
      "|  dec_layers.0.mha_1.W_Q.weight   |   262144   |\n",
      "|   dec_layers.0.mha_1.W_Q.bias    |    512     |\n",
      "|  dec_layers.0.mha_1.W_K.weight   |   262144   |\n",
      "|   dec_layers.0.mha_1.W_K.bias    |    512     |\n",
      "|  dec_layers.0.mha_1.W_V.weight   |   262144   |\n",
      "|   dec_layers.0.mha_1.W_V.bias    |    512     |\n",
      "|  dec_layers.0.mha_2.W_Q.weight   |   262144   |\n",
      "|   dec_layers.0.mha_2.W_Q.bias    |    512     |\n",
      "|  dec_layers.0.mha_2.W_K.weight   |   262144   |\n",
      "|   dec_layers.0.mha_2.W_K.bias    |    512     |\n",
      "|  dec_layers.0.mha_2.W_V.weight   |   262144   |\n",
      "|   dec_layers.0.mha_2.W_V.bias    |    512     |\n",
      "| dec_layers.0.ffn.linear_1.weight |  1048576   |\n",
      "|  dec_layers.0.ffn.linear_1.bias  |    2048    |\n",
      "| dec_layers.0.ffn.linear_2.weight |  1048576   |\n",
      "|  dec_layers.0.ffn.linear_2.bias  |    512     |\n",
      "|  dec_layers.0.layer_norm.weight  |    512     |\n",
      "|   dec_layers.0.layer_norm.bias   |    512     |\n",
      "|  dec_layers.1.mha_1.W_Q.weight   |   262144   |\n",
      "|   dec_layers.1.mha_1.W_Q.bias    |    512     |\n",
      "|  dec_layers.1.mha_1.W_K.weight   |   262144   |\n",
      "|   dec_layers.1.mha_1.W_K.bias    |    512     |\n",
      "|  dec_layers.1.mha_1.W_V.weight   |   262144   |\n",
      "|   dec_layers.1.mha_1.W_V.bias    |    512     |\n",
      "|  dec_layers.1.mha_2.W_Q.weight   |   262144   |\n",
      "|   dec_layers.1.mha_2.W_Q.bias    |    512     |\n",
      "|  dec_layers.1.mha_2.W_K.weight   |   262144   |\n",
      "|   dec_layers.1.mha_2.W_K.bias    |    512     |\n",
      "|  dec_layers.1.mha_2.W_V.weight   |   262144   |\n",
      "|   dec_layers.1.mha_2.W_V.bias    |    512     |\n",
      "| dec_layers.1.ffn.linear_1.weight |  1048576   |\n",
      "|  dec_layers.1.ffn.linear_1.bias  |    2048    |\n",
      "| dec_layers.1.ffn.linear_2.weight |  1048576   |\n",
      "|  dec_layers.1.ffn.linear_2.bias  |    512     |\n",
      "|  dec_layers.1.layer_norm.weight  |    512     |\n",
      "|   dec_layers.1.layer_norm.bias   |    512     |\n",
      "|  dec_layers.2.mha_1.W_Q.weight   |   262144   |\n",
      "|   dec_layers.2.mha_1.W_Q.bias    |    512     |\n",
      "|  dec_layers.2.mha_1.W_K.weight   |   262144   |\n",
      "|   dec_layers.2.mha_1.W_K.bias    |    512     |\n",
      "|  dec_layers.2.mha_1.W_V.weight   |   262144   |\n",
      "|   dec_layers.2.mha_1.W_V.bias    |    512     |\n",
      "|  dec_layers.2.mha_2.W_Q.weight   |   262144   |\n",
      "|   dec_layers.2.mha_2.W_Q.bias    |    512     |\n",
      "|  dec_layers.2.mha_2.W_K.weight   |   262144   |\n",
      "|   dec_layers.2.mha_2.W_K.bias    |    512     |\n",
      "|  dec_layers.2.mha_2.W_V.weight   |   262144   |\n",
      "|   dec_layers.2.mha_2.W_V.bias    |    512     |\n",
      "| dec_layers.2.ffn.linear_1.weight |  1048576   |\n",
      "|  dec_layers.2.ffn.linear_1.bias  |    2048    |\n",
      "| dec_layers.2.ffn.linear_2.weight |  1048576   |\n",
      "|  dec_layers.2.ffn.linear_2.bias  |    512     |\n",
      "|  dec_layers.2.layer_norm.weight  |    512     |\n",
      "|   dec_layers.2.layer_norm.bias   |    512     |\n",
      "|  dec_layers.3.mha_1.W_Q.weight   |   262144   |\n",
      "|   dec_layers.3.mha_1.W_Q.bias    |    512     |\n",
      "|  dec_layers.3.mha_1.W_K.weight   |   262144   |\n",
      "|   dec_layers.3.mha_1.W_K.bias    |    512     |\n",
      "|  dec_layers.3.mha_1.W_V.weight   |   262144   |\n",
      "|   dec_layers.3.mha_1.W_V.bias    |    512     |\n",
      "|  dec_layers.3.mha_2.W_Q.weight   |   262144   |\n",
      "|   dec_layers.3.mha_2.W_Q.bias    |    512     |\n",
      "|  dec_layers.3.mha_2.W_K.weight   |   262144   |\n",
      "|   dec_layers.3.mha_2.W_K.bias    |    512     |\n",
      "|  dec_layers.3.mha_2.W_V.weight   |   262144   |\n",
      "|   dec_layers.3.mha_2.W_V.bias    |    512     |\n",
      "| dec_layers.3.ffn.linear_1.weight |  1048576   |\n",
      "|  dec_layers.3.ffn.linear_1.bias  |    2048    |\n",
      "| dec_layers.3.ffn.linear_2.weight |  1048576   |\n",
      "|  dec_layers.3.ffn.linear_2.bias  |    512     |\n",
      "|  dec_layers.3.layer_norm.weight  |    512     |\n",
      "|   dec_layers.3.layer_norm.bias   |    512     |\n",
      "|  dec_layers.4.mha_1.W_Q.weight   |   262144   |\n",
      "|   dec_layers.4.mha_1.W_Q.bias    |    512     |\n",
      "|  dec_layers.4.mha_1.W_K.weight   |   262144   |\n",
      "|   dec_layers.4.mha_1.W_K.bias    |    512     |\n",
      "|  dec_layers.4.mha_1.W_V.weight   |   262144   |\n",
      "|   dec_layers.4.mha_1.W_V.bias    |    512     |\n",
      "|  dec_layers.4.mha_2.W_Q.weight   |   262144   |\n",
      "|   dec_layers.4.mha_2.W_Q.bias    |    512     |\n",
      "|  dec_layers.4.mha_2.W_K.weight   |   262144   |\n",
      "|   dec_layers.4.mha_2.W_K.bias    |    512     |\n",
      "|  dec_layers.4.mha_2.W_V.weight   |   262144   |\n",
      "|   dec_layers.4.mha_2.W_V.bias    |    512     |\n",
      "| dec_layers.4.ffn.linear_1.weight |  1048576   |\n",
      "|  dec_layers.4.ffn.linear_1.bias  |    2048    |\n",
      "| dec_layers.4.ffn.linear_2.weight |  1048576   |\n",
      "|  dec_layers.4.ffn.linear_2.bias  |    512     |\n",
      "|  dec_layers.4.layer_norm.weight  |    512     |\n",
      "|   dec_layers.4.layer_norm.bias   |    512     |\n",
      "|  dec_layers.5.mha_1.W_Q.weight   |   262144   |\n",
      "|   dec_layers.5.mha_1.W_Q.bias    |    512     |\n",
      "|  dec_layers.5.mha_1.W_K.weight   |   262144   |\n",
      "|   dec_layers.5.mha_1.W_K.bias    |    512     |\n",
      "|  dec_layers.5.mha_1.W_V.weight   |   262144   |\n",
      "|   dec_layers.5.mha_1.W_V.bias    |    512     |\n",
      "|  dec_layers.5.mha_2.W_Q.weight   |   262144   |\n",
      "|   dec_layers.5.mha_2.W_Q.bias    |    512     |\n",
      "|  dec_layers.5.mha_2.W_K.weight   |   262144   |\n",
      "|   dec_layers.5.mha_2.W_K.bias    |    512     |\n",
      "|  dec_layers.5.mha_2.W_V.weight   |   262144   |\n",
      "|   dec_layers.5.mha_2.W_V.bias    |    512     |\n",
      "| dec_layers.5.ffn.linear_1.weight |  1048576   |\n",
      "|  dec_layers.5.ffn.linear_1.bias  |    2048    |\n",
      "| dec_layers.5.ffn.linear_2.weight |  1048576   |\n",
      "|  dec_layers.5.ffn.linear_2.bias  |    512     |\n",
      "|  dec_layers.5.layer_norm.weight  |    512     |\n",
      "|   dec_layers.5.layer_norm.bias   |    512     |\n",
      "|          linear.weight           |  1536000   |\n",
      "|           linear.bias            |    3000    |\n",
      "+----------------------------------+------------+\n",
      "전체 모델 가중치 수: 43747256\n",
      "전체 모델 가중치 수: 43747256\n",
      "학습 시작\n",
      "epoch 0 시작\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 0 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 1 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 2 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 3 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 4 done.\n",
      "epoch 1 시작\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 0 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 1 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 2 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 3 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 4 done.\n",
      "epoch 2 시작\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 0 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 1 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 2 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 3 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 4 done.\n",
      "epoch 3 시작\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 0 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 1 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 2 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 3 done.\n",
      "틀 tensor([[[ True, False, False,  ..., False, False, False],\n",
      "         [ True,  True, False,  ..., False, False, False],\n",
      "         [ True,  True,  True,  ..., False, False, False],\n",
      "         ...,\n",
      "         [ True,  True,  True,  ...,  True, False, False],\n",
      "         [ True,  True,  True,  ...,  True,  True, False],\n",
      "         [ True,  True,  True,  ...,  True,  True,  True]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "마스크 결과 tensor([[[[1268,    0,    0,  ...,    0,    0,    0],\n",
      "          [1786, 1786,    0,  ...,    0,    0,    0],\n",
      "          [1031, 1031, 1031,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [2558, 2558, 2558,  ..., 2558,    0,    0],\n",
      "          [1226, 1226, 1226,  ..., 1226, 1226,    0],\n",
      "          [1416, 1416, 1416,  ..., 1416, 1416, 1416]]],\n",
      "\n",
      "\n",
      "        [[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "          [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "          [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "          [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "          [ 942,  942,  942,  ...,  942,  942,  942]]],\n",
      "\n",
      "\n",
      "        [[[2050,    0,    0,  ...,    0,    0,    0],\n",
      "          [1164, 1164,    0,  ...,    0,    0,    0],\n",
      "          [1586, 1586, 1586,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1686, 1686, 1686,  ..., 1686,    0,    0],\n",
      "          [1956, 1956, 1956,  ..., 1956, 1956,    0],\n",
      "          [2683, 2683, 2683,  ..., 2683, 2683, 2683]]],\n",
      "\n",
      "\n",
      "        [[[2518,    0,    0,  ...,    0,    0,    0],\n",
      "          [ 795,  795,    0,  ...,    0,    0,    0],\n",
      "          [ 126,  126,  126,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [ 718,  718,  718,  ...,  718,    0,    0],\n",
      "          [ 267,  267,  267,  ...,  267,  267,    0],\n",
      "          [ 499,  499,  499,  ...,  499,  499,  499]]],\n",
      "\n",
      "\n",
      "        [[[ 684,    0,    0,  ...,    0,    0,    0],\n",
      "          [2429, 2429,    0,  ...,    0,    0,    0],\n",
      "          [ 470,  470,  470,  ...,    0,    0,    0],\n",
      "          ...,\n",
      "          [1879, 1879, 1879,  ..., 1879,    0,    0],\n",
      "          [2702, 2702, 2702,  ..., 2702, 2702,    0],\n",
      "          [1161, 1161, 1161,  ..., 1161, 1161, 1161]]]])\n",
      "마스크 모양 torch.Size([5, 1, 100, 100])\n",
      "tensor([[[1092,    0,    0,  ...,    0,    0,    0],\n",
      "         [1582, 1582,    0,  ...,    0,    0,    0],\n",
      "         [2829, 2829, 2829,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [ 674,  674,  674,  ...,  674,    0,    0],\n",
      "         [ 849,  849,  849,  ...,  849,  849,    0],\n",
      "         [ 942,  942,  942,  ...,  942,  942,  942]]])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "전 torch.Size([100])\n",
      "후 torch.Size([100, 1])\n",
      "결과 torch.Size([100, 512])\n",
      "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
      "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
      "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
      "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
      "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
      "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
      "        144., 146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166.,\n",
      "        168., 170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190.,\n",
      "        192., 194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214.,\n",
      "        216., 218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238.,\n",
      "        240., 242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
      "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284., 286.,\n",
      "        288., 290., 292., 294., 296., 298., 300., 302., 304., 306., 308., 310.,\n",
      "        312., 314., 316., 318., 320., 322., 324., 326., 328., 330., 332., 334.,\n",
      "        336., 338., 340., 342., 344., 346., 348., 350., 352., 354., 356., 358.,\n",
      "        360., 362., 364., 366., 368., 370., 372., 374., 376., 378., 380., 382.,\n",
      "        384., 386., 388., 390., 392., 394., 396., 398., 400., 402., 404., 406.,\n",
      "        408., 410., 412., 414., 416., 418., 420., 422., 424., 426., 428., 430.,\n",
      "        432., 434., 436., 438., 440., 442., 444., 446., 448., 450., 452., 454.,\n",
      "        456., 458., 460., 462., 464., 466., 468., 470., 472., 474., 476., 478.,\n",
      "        480., 482., 484., 486., 488., 490., 492., 494., 496., 498., 500., 502.,\n",
      "        504., 506., 508., 510.])\n",
      "최종 모양 torch.Size([1, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "디코더입력데이터모양 torch.Size([5, 100, 512])\n",
      "self attention 후데이터모양 torch.Size([5, 100, 512])\n",
      "cross attention 후 데이터 모양 torch.Size([5, 100, 512])\n",
      "feed forward 후데이터모양 torch.Size([5, 100, 512])\n",
      "최종 출력 모양 torch.Size([5, 100])\n",
      "최종 출력 내용 tensor([[2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [ 569, 2634, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  736,  867,\n",
      "         2555,  569, 2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386,  736, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2634, 2555, 2555,  242, 2399,  242, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 1386, 1386, 2555, 2555, 2555,  242, 1465, 2555,\n",
      "         2555, 2555, 2555, 1386, 2555, 2634, 2555, 2555, 1386,  569, 2555, 2019,\n",
      "         2555, 2555, 2555, 2555],\n",
      "        [2555, 2321, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2321,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555,\n",
      "         1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2321, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 1465,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 2555],\n",
      "        [1481, 2638, 2555, 2406, 2555, 2555, 2555, 2555, 1386, 1386, 2555, 2555,\n",
      "         2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555, 2555, 2555,\n",
      "          242, 2555, 2555, 2555, 2555,  242, 2555, 1386, 2555, 2555, 2555, 2555,\n",
      "         2555,  242, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 1386, 2555,  242,\n",
      "         2555, 2555, 2555,  242,  242, 2555,  242,  242,  242, 2555,  242,  242,\n",
      "         2555, 2555, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 1465, 2555, 2555, 2555,  242, 2555, 2555, 1465, 2634, 1465, 2555,\n",
      "          242, 2555, 2555, 2555, 2555, 2555, 1465, 2555,  242, 1386, 2555,  569,\n",
      "         2555, 2555, 2555, 1386],\n",
      "        [2555, 1386, 1386, 2555,  811,  867, 1386, 1386, 1386, 2555, 2555, 2555,\n",
      "         2555, 1386, 2555, 1386, 2555, 2555, 2555, 2555, 2555, 2555,  242, 2555,\n",
      "         2555, 2555, 2555, 1386, 1386, 2555, 1386, 2555, 1386, 2555, 2555, 1386,\n",
      "         2555,  242, 2555,  569, 2555, 2555, 2555, 2555, 1386, 1386, 1386, 2555,\n",
      "         2555, 2555, 2555,  569, 2555, 2555, 2555, 2555, 2555, 2555, 2555,  242,\n",
      "         2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 1386, 1386, 2555, 2555, 1386, 1386, 2555, 1386, 1386, 2555,\n",
      "         2555, 1465, 1386, 2555, 2555, 2555, 1465, 2555, 2555, 2555, 2555, 2555,\n",
      "         2555, 2555, 2555, 1386]])\n",
      "    batch 4 done.\n",
      "학습 종료\n",
      "걸린 시간 5.799620628356934\n"
     ]
    }
   ],
   "source": [
    "# 11번 블럭\n",
    "# 트랜스포머 학습\n",
    "\n",
    "model = My_Transformer(d_model, num_heads, num_layers, d_ff, max_seq)\n",
    "count_parameters(model)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"전체 모델 가중치 수: {total_params}\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 학습 시작\n",
    "begin = time()\n",
    "print(\"학습 시작\")\n",
    "for epoch in range(tot_epoch):\n",
    "    print(\"epoch\", epoch, \"시작\")\n",
    "    for batch in range(batch_size):\n",
    "        output = model(src_data, tgt_data)\n",
    "        pred = output.contiguous().view(-1).float().requires_grad_()\n",
    "        truth = tgt_data.contiguous().view(-1).float()\n",
    "\n",
    "        loss = criterion(pred, truth)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"    batch\", batch, \"done.\")\n",
    "print(\"학습 종료\")\n",
    "end = time()\n",
    "print(\"걸린 시간\", end - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "696fdcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 모델 가중치 수: 43747256\n",
      "학습 시작\n",
      "epoch 0 시작\n",
      "    batch 0 done.\n",
      "    batch 1 done.\n",
      "    batch 2 done.\n",
      "    batch 3 done.\n",
      "    batch 4 done.\n",
      "epoch 1 시작\n",
      "    batch 0 done.\n",
      "    batch 1 done.\n",
      "    batch 2 done.\n",
      "    batch 3 done.\n",
      "    batch 4 done.\n",
      "epoch 2 시작\n",
      "    batch 0 done.\n",
      "    batch 1 done.\n",
      "    batch 2 done.\n",
      "    batch 3 done.\n",
      "    batch 4 done.\n",
      "epoch 3 시작\n",
      "    batch 0 done.\n",
      "    batch 1 done.\n",
      "    batch 2 done.\n",
      "    batch 3 done.\n",
      "    batch 4 done.\n",
      "학습 종료\n",
      "걸린 시간 3.978344202041626\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "# 2번 블록 - 하이퍼파라미터 정의\n",
    "src_vocab = 2500  # 입력 어휘 사전 크기 (입력 토큰 종류 수)\n",
    "tgt_vocab = 3000  # 출력 어휘 사전 크기 (출력 토큰 종류 수)\n",
    "d_model = 512  # 단어 임베딩 차원 수 (각 단어를 512차원 벡터로 표현)\n",
    "num_heads = 8  # 멀티헤드 어텐션에서의 헤드 수 (각기 다른 8개의 시선으로 어텐션 수행)\n",
    "d_ff = 2048  # Feed-Forward Network의 은닉층 차원 수\n",
    "num_layers = 6  # 인코더와 디코더의 층 수 (각각 6층)\n",
    "max_seq = 100  # 문장의 최대 길이 (한 문장에 들어갈 수 있는 최대 토큰 수)\n",
    "tot_epoch = 4  # 학습 epoch 수 (전체 데이터를 4회 반복 학습)\n",
    "batch_size = 5  # 배치 크기 (한 번에 처리할 문장 수 = 5개)\n",
    "\n",
    "# 3번 블록 - 임의 데이터 생성\n",
    "src_data = torch.randint(\n",
    "    0, src_vocab, (batch_size, max_seq)\n",
    ")  # [5, 100] 형태의 입력 시퀀스\n",
    "# 값은 0~2499 범위의 정수. 각 값은 단어를 나타냄.\n",
    "tgt_data = torch.randint(\n",
    "    0, tgt_vocab, (batch_size, max_seq)\n",
    ")  # [5, 100] 형태의 출력 시퀀스\n",
    "\n",
    "\n",
    "# 4번 블록 - 멀티헤드 어텐션\n",
    "class My_MHA(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(My_MHA, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = d_model // num_heads  # 각 헤드가 처리할 차원 수: 512 // 8 = 64\n",
    "\n",
    "        # Q, K, V 생성을 위한 선형 변환 레이어. 각기 다른 파라미터를 사용하여 독립적으로 학습됨\n",
    "        self.W_Q = nn.Linear(\n",
    "            d_model, d_model\n",
    "        )  # 입력 벡터를 Query 벡터로 변환 (512→512)\n",
    "        self.W_K = nn.Linear(d_model, d_model)  # 입력 벡터를 Key 벡터로 변환\n",
    "        self.W_V = nn.Linear(d_model, d_model)  # 입력 벡터를 Value 벡터로 변환\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.size(0)  # 배치 크기 추출\n",
    "        # [B, T, 512] → [B, T, 8, 64]로 변형 후\n",
    "        # transpose로 [B, 8, T, 64]로 바꿔 각 헤드에 대해 독립 연산 가능하게 함\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.d_head)\n",
    "        return x.transpose(1, 2)\n",
    "\n",
    "    def dot_prod(self, Q, K, V, mask):\n",
    "        # 어텐션 스코어 계산: [Q]·[K]^T / sqrt(d_head)\n",
    "        score = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(self.d_head)\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(\n",
    "                mask == 0, -1e9\n",
    "            )  # 마스크가 0인 곳은 매우 작은 값으로\n",
    "        prob = torch.softmax(score, dim=-1)  # 어텐션 확률 분포\n",
    "        return torch.matmul(prob, V)  # 가중합 결과\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # [B, 8, T, 64] → [B, T, 8, 64] → [B, T, 512]\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return x\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # Q, K, V 선형변환 및 헤드 분리\n",
    "        Q = self.split_heads(self.W_Q(q))\n",
    "        K = self.split_heads(self.W_K(k))\n",
    "        V = self.split_heads(self.W_V(v))\n",
    "        # 어텐션 적용 및 헤드 결합\n",
    "        attn = self.dot_prod(Q, K, V, mask)\n",
    "        return self.combine_heads(attn)\n",
    "\n",
    "\n",
    "# 5번 블록 - Feed Forward\n",
    "class My_FFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(My_FFN, self).__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)  # 512 → 2048\n",
    "        self.relu = nn.ReLU()  # 비선형성 부여\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)  # 2048 → 512\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_2(self.relu(self.linear_1(x)))\n",
    "\n",
    "\n",
    "# 6번 블록 - 인코더 블록\n",
    "class My_Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(My_Encoder, self).__init__()\n",
    "        self.mha = My_MHA(d_model, num_heads)\n",
    "        self.ffn = My_FFN(d_model, d_ff)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)  # 정규화\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        z = self.mha(x, x, x, mask)  # 셀프 어텐션\n",
    "        z = self.layer_norm(x + z)  # 잔차 연결 + 정규화\n",
    "        w = self.ffn(z)\n",
    "        return self.layer_norm(w + z)  # 잔차 연결 + 정규화\n",
    "\n",
    "\n",
    "# 7번 블록 - 위치 인코딩\n",
    "class My_Position(nn.Module):\n",
    "    def __init__(self, d_model, max_seq):\n",
    "        super(My_Position, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_seq = max_seq\n",
    "\n",
    "    def pos_enc(self, x):\n",
    "        k = torch.arange(0, self.max_seq, 1).float().unsqueeze(1)  # 위치 인덱스\n",
    "        result = torch.zeros(self.max_seq, self.d_model)\n",
    "        twoi = torch.arange(0, self.d_model, 2).float()  # 짝수 차원 인덱스\n",
    "        result[:, 0::2] = torch.sin(k / (10000 ** (twoi / self.d_model)))\n",
    "        result[:, 1::2] = torch.cos(k / (10000 ** (twoi / self.d_model)))\n",
    "        return result.unsqueeze(0)  # [1, max_seq, d_model]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pos_enc(x)\n",
    "\n",
    "\n",
    "# 8번 블록 - 디코더 블록\n",
    "class My_Decoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(My_Decoder, self).__init__()\n",
    "        self.mha_1 = My_MHA(d_model, num_heads)  # 디코더 셀프 어텐션\n",
    "        self.mha_2 = My_MHA(d_model, num_heads)  # 인코더-디코더 어텐션\n",
    "        self.ffn = My_FFN(d_model, d_ff)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, tgt_mask):\n",
    "        z = self.mha_1(x, x, x, tgt_mask)  # 자기 자신에 대한 셀프 어텐션\n",
    "        z = self.layer_norm(x + z)\n",
    "        y = self.mha_2(z, enc_out, enc_out, src_mask)  # 인코더 출력에 대한 어텐션\n",
    "        y = self.layer_norm(z + y)\n",
    "        w = self.ffn(y)\n",
    "        return self.layer_norm(w + y)\n",
    "\n",
    "\n",
    "# 9번 블록 - 전체 트랜스포머\n",
    "class My_Transformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_layers, d_ff, max_seq):\n",
    "        super(My_Transformer, self).__init__()\n",
    "        self.enc_embed = nn.Embedding(src_vocab, d_model)\n",
    "        self.dec_embed = nn.Embedding(tgt_vocab, d_model)\n",
    "        self.pos_enc = My_Position(d_model, max_seq)\n",
    "        self.enc_layers = nn.ModuleList(\n",
    "            [My_Encoder(d_model, num_heads, d_ff) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.dec_layers = nn.ModuleList(\n",
    "            [My_Decoder(d_model, num_heads, d_ff) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.linear = nn.Linear(d_model, tgt_vocab)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def make_mask(self, src, tgt):\n",
    "        src_mask = None  # 현재 구현에서는 src_mask 생략\n",
    "        tgt_mask = tgt.unsqueeze(1).unsqueeze(3)\n",
    "        tmp = torch.ones(1, max_seq, max_seq)\n",
    "        mask = torch.tril(tmp).bool()  # 하삼각 마스킹 (미래 정보 차단)\n",
    "        return src_mask, tgt_mask * mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.make_mask(src, tgt)\n",
    "        src_embed = self.enc_embed(src) + self.pos_enc(src)\n",
    "        tgt_embed = self.dec_embed(tgt) + self.pos_enc(tgt)\n",
    "        enc_out = src_embed\n",
    "        for layer in self.enc_layers:\n",
    "            enc_out = layer(enc_out, src_mask)\n",
    "        dec_out = tgt_embed\n",
    "        for layer in self.dec_layers:\n",
    "            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n",
    "        out = self.linear(dec_out)\n",
    "        out = self.softmax(out)\n",
    "        return torch.argmax(out, dim=-1)\n",
    "\n",
    "\n",
    "# 10번 블록 - 파라미터 수 계산\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"전체 모델 가중치 수: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "\n",
    "# 11번 블록 - 트랜스포머 학습 루프\n",
    "model = My_Transformer(d_model, num_heads, num_layers, d_ff, max_seq)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"전체 모델 가중치 수: {total_params}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "begin = time()\n",
    "print(\"학습 시작\")\n",
    "for epoch in range(tot_epoch):\n",
    "    print(\"epoch\", epoch, \"시작\")\n",
    "    for batch in range(batch_size):\n",
    "        output = model(src_data, tgt_data)  # [5, 100]\n",
    "        pred = output.contiguous().view(-1).float().requires_grad_()\n",
    "        truth = tgt_data.contiguous().view(-1).float()\n",
    "\n",
    "        loss = criterion(pred, truth)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"    batch\", batch, \"done.\")\n",
    "print(\"학습 종료\")\n",
    "end = time()\n",
    "print(\"걸린 시간\", end - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a4ce7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 모델 가중치 수: 43747256\n",
      "학습 시작\n",
      "epoch 0 시작\n",
      "    batch 0 done.\n",
      "    batch 1 done.\n",
      "    batch 2 done.\n",
      "    batch 3 done.\n",
      "    batch 4 done.\n",
      "epoch 1 시작\n",
      "    batch 0 done.\n",
      "    batch 1 done.\n",
      "    batch 2 done.\n",
      "    batch 3 done.\n",
      "    batch 4 done.\n",
      "epoch 2 시작\n",
      "    batch 0 done.\n",
      "    batch 1 done.\n",
      "    batch 2 done.\n",
      "    batch 3 done.\n",
      "    batch 4 done.\n",
      "epoch 3 시작\n",
      "    batch 0 done.\n",
      "    batch 1 done.\n",
      "    batch 2 done.\n",
      "    batch 3 done.\n",
      "    batch 4 done.\n",
      "학습 종료\n",
      "걸린 시간 3.876668930053711\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "# 2번 블록 - 하이퍼파라미터 정의\n",
    "src_vocab = 2500  # 입력 어휘 사전 크기 (입력 토큰 종류 수)\n",
    "tgt_vocab = 3000  # 출력 어휘 사전 크기 (출력 토큰 종류 수)\n",
    "d_model = 512  # 단어 임베딩 차원 수 (각 단어를 512차원 벡터로 표현)\n",
    "num_heads = 8  # 멀티헤드 어텐션에서의 헤드 수 (각기 다른 8개의 시선으로 어텐션 수행)\n",
    "d_ff = 2048  # Feed-Forward Network의 은닉층 차원 수\n",
    "num_layers = 6  # 인코더와 디코더의 층 수 (각각 6층)\n",
    "max_seq = 100  # 문장의 최대 길이 (한 문장에 들어갈 수 있는 최대 토큰 수)\n",
    "tot_epoch = 4  # 학습 epoch 수 (전체 데이터를 4회 반복 학습)\n",
    "batch_size = 5  # 배치 크기 (한 번에 처리할 문장 수 = 5개)\n",
    "\n",
    "# 3번 블록 - 임의 데이터 생성\n",
    "src_data = torch.randint(\n",
    "    0, src_vocab, (batch_size, max_seq)\n",
    ")  # [5, 100] 형태의 입력 시퀀스\n",
    "# 값은 0~2499 범위의 정수. 각 값은 단어를 나타냄.\n",
    "tgt_data = torch.randint(\n",
    "    0, tgt_vocab, (batch_size, max_seq)\n",
    ")  # [5, 100] 형태의 출력 시퀀스\n",
    "\n",
    "\n",
    "# 4번 블록 - 멀티헤드 어텐션\n",
    "class My_MHA(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(My_MHA, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = d_model // num_heads  # 각 헤드가 처리할 차원 수: 512 // 8 = 64\n",
    "\n",
    "        # Q, K, V 생성을 위한 선형 변환 레이어. 각기 다른 파라미터를 사용하여 독립적으로 학습됨\n",
    "        self.W_Q = nn.Linear(\n",
    "            d_model, d_model\n",
    "        )  # 입력 벡터를 Query 벡터로 변환 (512→512)\n",
    "        self.W_K = nn.Linear(d_model, d_model)  # 입력 벡터를 Key 벡터로 변환\n",
    "        self.W_V = nn.Linear(d_model, d_model)  # 입력 벡터를 Value 벡터로 변환\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.size(0)  # 배치 크기 추출\n",
    "        # [B, T, 512] → [B, T, 8, 64]로 변형 후\n",
    "        # transpose로 [B, 8, T, 64]로 바꿔 각 헤드에 대해 독립 연산 가능하게 함\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.d_head)\n",
    "        return x.transpose(1, 2)  # 헤드 축 앞으로 이동\n",
    "\n",
    "    def dot_prod(self, Q, K, V, mask):\n",
    "        # 어텐션 스코어 계산: [Q]·[K]^T / sqrt(d_head)\n",
    "        score = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(self.d_head)\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(\n",
    "                mask == 0, -1e9\n",
    "            )  # 마스크가 0인 곳은 매우 작은 값으로\n",
    "        prob = torch.softmax(score, dim=-1)  # 어텐션 확률 분포\n",
    "        return torch.matmul(prob, V)  # 가중합 결과: [B, H, T, D]\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # [B, 8, T, 64] → [B, T, 8, 64]로 transpose → view로 다시 합침\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return x  # [B, T, 512]\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        Q = self.split_heads(self.W_Q(q))  # [B, T, 512] → [B, 8, T, 64]\n",
    "        K = self.split_heads(self.W_K(k))\n",
    "        V = self.split_heads(self.W_V(v))\n",
    "        attn = self.dot_prod(Q, K, V, mask)  # 어텐션 연산\n",
    "        return self.combine_heads(attn)  # 다시 [B, T, 512]로 병합\n",
    "\n",
    "\n",
    "# 5번 블록 - Feed Forward\n",
    "class My_FFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(My_FFN, self).__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)  # 512 → 2048\n",
    "        self.relu = nn.ReLU()  # 비선형성 부여\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)  # 2048 → 512\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_2(self.relu(self.linear_1(x)))  # [B, T, 512] 유지\n",
    "\n",
    "\n",
    "# 6번 블록 - 인코더 블록\n",
    "class My_Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(My_Encoder, self).__init__()\n",
    "        self.mha = My_MHA(d_model, num_heads)\n",
    "        self.ffn = My_FFN(d_model, d_ff)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)  # 정규화 레이어\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        z = self.mha(x, x, x, mask)  # 셀프 어텐션\n",
    "        z = self.layer_norm(x + z)  # 잔차 연결 + 정규화\n",
    "        w = self.ffn(z)  # FFN 통과\n",
    "        return self.layer_norm(w + z)  # 잔차 연결 + 정규화\n",
    "\n",
    "\n",
    "# 7번 블록 - 위치 인코딩\n",
    "class My_Position(nn.Module):\n",
    "    def __init__(self, d_model, max_seq):\n",
    "        super(My_Position, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_seq = max_seq\n",
    "\n",
    "    def pos_enc(self, x):\n",
    "        k = torch.arange(0, self.max_seq, 1).float().unsqueeze(1)  # 위치 인덱스\n",
    "        result = torch.zeros(self.max_seq, self.d_model)\n",
    "        twoi = torch.arange(0, self.d_model, 2).float()\n",
    "        result[:, 0::2] = torch.sin(k / (10000 ** (twoi / self.d_model)))\n",
    "        result[:, 1::2] = torch.cos(k / (10000 ** (twoi / self.d_model)))\n",
    "        return result.unsqueeze(0)  # [1, max_seq, d_model]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pos_enc(x)\n",
    "\n",
    "\n",
    "# 8번 블록 - 디코더 블록\n",
    "class My_Decoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(My_Decoder, self).__init__()\n",
    "        self.mha_1 = My_MHA(d_model, num_heads)  # 디코더 셀프 어텐션\n",
    "        self.mha_2 = My_MHA(d_model, num_heads)  # 인코더-디코더 어텐션\n",
    "        self.ffn = My_FFN(d_model, d_ff)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, tgt_mask):\n",
    "        z = self.mha_1(x, x, x, tgt_mask)  # 자기 자신에 대한 어텐션\n",
    "        z = self.layer_norm(x + z)\n",
    "        y = self.mha_2(z, enc_out, enc_out, src_mask)  # 인코더에 대한 어텐션\n",
    "        y = self.layer_norm(z + y)\n",
    "        w = self.ffn(y)\n",
    "        return self.layer_norm(w + y)\n",
    "\n",
    "\n",
    "# 9번 블록 - 전체 트랜스포머\n",
    "class My_Transformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_layers, d_ff, max_seq):\n",
    "        super(My_Transformer, self).__init__()\n",
    "        self.enc_embed = nn.Embedding(src_vocab, d_model)\n",
    "        self.dec_embed = nn.Embedding(tgt_vocab, d_model)\n",
    "        self.pos_enc = My_Position(d_model, max_seq)\n",
    "        self.enc_layers = nn.ModuleList(\n",
    "            [My_Encoder(d_model, num_heads, d_ff) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.dec_layers = nn.ModuleList(\n",
    "            [My_Decoder(d_model, num_heads, d_ff) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.linear = nn.Linear(d_model, tgt_vocab)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def make_mask(self, src, tgt):\n",
    "        src_mask = None\n",
    "        tgt_mask = tgt.unsqueeze(1).unsqueeze(3)  # [B, 1, T, 1]\n",
    "        tmp = torch.ones(1, max_seq, max_seq)\n",
    "        mask = torch.tril(tmp).bool()  # 미래를 가리지 않도록 하삼각 마스크\n",
    "        return src_mask, tgt_mask * mask  # [B, T, T] 형태로 적용\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.make_mask(src, tgt)\n",
    "        src_embed = self.enc_embed(src) + self.pos_enc(src)  # [B, T, 512]\n",
    "        tgt_embed = self.dec_embed(tgt) + self.pos_enc(tgt)\n",
    "\n",
    "        enc_out = src_embed\n",
    "        for layer in self.enc_layers:\n",
    "            enc_out = layer(enc_out, src_mask)\n",
    "\n",
    "        dec_out = tgt_embed\n",
    "        for layer in self.dec_layers:\n",
    "            dec_out = layer(dec_out, enc_out, src_mask, tgt_mask)\n",
    "\n",
    "        out = self.linear(dec_out)  # [B, T, 3000]\n",
    "        out = self.softmax(out)\n",
    "        return torch.argmax(out, dim=-1)  # 예측 결과: [B, T]\n",
    "\n",
    "\n",
    "# 10번 블록 - 파라미터 수 계산\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"전체 모델 가중치 수: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "\n",
    "# 11번 블록 - 트랜스포머 학습 루프\n",
    "model = My_Transformer(d_model, num_heads, num_layers, d_ff, max_seq)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"전체 모델 가중치 수: {total_params}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "begin = time()\n",
    "print(\"학습 시작\")\n",
    "for epoch in range(tot_epoch):\n",
    "    print(\"epoch\", epoch, \"시작\")\n",
    "    for batch in range(batch_size):\n",
    "        output = model(src_data, tgt_data)  # [5, 100]\n",
    "        pred = (\n",
    "            output.contiguous().view(-1).float().requires_grad_()\n",
    "        )  # 예측 결과를 flat하게\n",
    "        truth = tgt_data.contiguous().view(-1).float()  # 정답도 같은 형태로\n",
    "\n",
    "        loss = criterion(pred, truth)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"    batch\", batch, \"done.\")\n",
    "print(\"학습 종료\")\n",
    "end = time()\n",
    "print(\"걸린 시간\", end - begin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api_part1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
