{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc31479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\main\\miniconda3\\envs\\openai_api_part1\\lib\\site-packages (from torch) (4.13.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\main\\miniconda3\\envs\\openai_api_part1\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\main\\miniconda3\\envs\\openai_api_part1\\lib\\site-packages (from torch) (78.1.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\main\\miniconda3\\envs\\openai_api_part1\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   ---------------------------------------- 6/6 [torch]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.5.0 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss : 1.0685\n",
      "Epoch [2/100], Loss : 1.1138\n",
      "Epoch [3/100], Loss : 1.1181\n",
      "Epoch [4/100], Loss : 1.0656\n",
      "Epoch [5/100], Loss : 1.0622\n",
      "Epoch [6/100], Loss : 1.0639\n",
      "Epoch [7/100], Loss : 1.0889\n",
      "Epoch [8/100], Loss : 1.0839\n",
      "Epoch [9/100], Loss : 1.0655\n",
      "Epoch [10/100], Loss : 1.0463\n",
      "Epoch [11/100], Loss : 1.0644\n",
      "Epoch [12/100], Loss : 1.0593\n",
      "Epoch [13/100], Loss : 1.0615\n",
      "Epoch [14/100], Loss : 1.0584\n",
      "Epoch [15/100], Loss : 1.0247\n",
      "Epoch [16/100], Loss : 1.0553\n",
      "Epoch [17/100], Loss : 1.0254\n",
      "Epoch [18/100], Loss : 1.0137\n",
      "Epoch [19/100], Loss : 1.0038\n",
      "Epoch [20/100], Loss : 0.9921\n",
      "Epoch [21/100], Loss : 0.9529\n",
      "Epoch [22/100], Loss : 0.9910\n",
      "Epoch [23/100], Loss : 1.0156\n",
      "Epoch [24/100], Loss : 0.8998\n",
      "Epoch [25/100], Loss : 0.9022\n",
      "Epoch [26/100], Loss : 0.8932\n",
      "Epoch [27/100], Loss : 0.9065\n",
      "Epoch [28/100], Loss : 0.8901\n",
      "Epoch [29/100], Loss : 0.8779\n",
      "Epoch [30/100], Loss : 0.9036\n",
      "Epoch [31/100], Loss : 0.8908\n",
      "Epoch [32/100], Loss : 0.9607\n",
      "Epoch [33/100], Loss : 0.9191\n",
      "Epoch [34/100], Loss : 0.7876\n",
      "Epoch [35/100], Loss : 0.9357\n",
      "Epoch [36/100], Loss : 0.8725\n",
      "Epoch [37/100], Loss : 0.8376\n",
      "Epoch [38/100], Loss : 0.7965\n",
      "Epoch [39/100], Loss : 0.7247\n",
      "Epoch [40/100], Loss : 0.8652\n",
      "Epoch [41/100], Loss : 0.8704\n",
      "Epoch [42/100], Loss : 0.8122\n",
      "Epoch [43/100], Loss : 0.7869\n",
      "Epoch [44/100], Loss : 0.8717\n",
      "Epoch [45/100], Loss : 0.8233\n",
      "Epoch [46/100], Loss : 0.7993\n",
      "Epoch [47/100], Loss : 0.7308\n",
      "Epoch [48/100], Loss : 0.7014\n",
      "Epoch [49/100], Loss : 0.7343\n",
      "Epoch [50/100], Loss : 0.8199\n",
      "Epoch [51/100], Loss : 0.7784\n",
      "Epoch [52/100], Loss : 0.7688\n",
      "Epoch [53/100], Loss : 0.8063\n",
      "Epoch [54/100], Loss : 0.7230\n",
      "Epoch [55/100], Loss : 0.7235\n",
      "Epoch [56/100], Loss : 0.7249\n",
      "Epoch [57/100], Loss : 0.7553\n",
      "Epoch [58/100], Loss : 0.7083\n",
      "Epoch [59/100], Loss : 0.7621\n",
      "Epoch [60/100], Loss : 0.8079\n",
      "Epoch [61/100], Loss : 0.7667\n",
      "Epoch [62/100], Loss : 0.7474\n",
      "Epoch [63/100], Loss : 0.7019\n",
      "Epoch [64/100], Loss : 0.7402\n",
      "Epoch [65/100], Loss : 0.7604\n",
      "Epoch [66/100], Loss : 0.6963\n",
      "Epoch [67/100], Loss : 0.7116\n",
      "Epoch [68/100], Loss : 0.6831\n",
      "Epoch [69/100], Loss : 0.6968\n",
      "Epoch [70/100], Loss : 0.6300\n",
      "Epoch [71/100], Loss : 0.6668\n",
      "Epoch [72/100], Loss : 0.6667\n",
      "Epoch [73/100], Loss : 0.6288\n",
      "Epoch [74/100], Loss : 0.6320\n",
      "Epoch [75/100], Loss : 0.6604\n",
      "Epoch [76/100], Loss : 0.6326\n",
      "Epoch [77/100], Loss : 0.6389\n",
      "Epoch [78/100], Loss : 0.6800\n",
      "Epoch [79/100], Loss : 0.6938\n",
      "Epoch [80/100], Loss : 0.6755\n",
      "Epoch [81/100], Loss : 0.6689\n",
      "Epoch [82/100], Loss : 0.6170\n",
      "Epoch [83/100], Loss : 0.6414\n",
      "Epoch [84/100], Loss : 0.6221\n",
      "Epoch [85/100], Loss : 0.6327\n",
      "Epoch [86/100], Loss : 0.7190\n",
      "Epoch [87/100], Loss : 0.6101\n",
      "Epoch [88/100], Loss : 0.6948\n",
      "Epoch [89/100], Loss : 0.5903\n",
      "Epoch [90/100], Loss : 0.6112\n",
      "Epoch [91/100], Loss : 0.6130\n",
      "Epoch [92/100], Loss : 0.6182\n",
      "Epoch [93/100], Loss : 0.5989\n",
      "Epoch [94/100], Loss : 0.5975\n",
      "Epoch [95/100], Loss : 0.6048\n",
      "Epoch [96/100], Loss : 0.5956\n",
      "Epoch [97/100], Loss : 0.6575\n",
      "Epoch [98/100], Loss : 0.5892\n",
      "Epoch [99/100], Loss : 0.5885\n",
      "Epoch [100/100], Loss : 0.6637\n",
      "Test Accuracy : 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "class IrisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 50)  # 입력 4, 출력 50\n",
    "        self.fc2 = nn.Linear(50, 30)  # 입력 50, 출력 30\n",
    "        self.fc3 = nn.Linear(30, 3)  # 입력 30, 출력 3\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return self.softmax(self.fc3(x))\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 모델, 손실함수, 옵티마이저 설정\n",
    "model = IrisModel()\n",
    "criterion = nn.CrossEntropyLoss()  # 손실함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        # 순전파\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 역전판\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss : {loss.item():.4f}\")\n",
    "\n",
    "# 평가\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_test_tensor).float().mean()\n",
    "    print(f\"Test Accuracy : {accuracy.item() * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api_part1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
